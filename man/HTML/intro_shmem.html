<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>intro_shmem</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body><h1><a href="../main.html">Index</a></h1>
<h1 id="name">Name</h1>
<pre><code> intro_shmem - Introduces logically shared distributed memory access
 routines</code></pre>
<h1 id="implementation">Implementation</h1>
<pre><code> Cray Linux Environment (CLE)</code></pre>
<h1 id="introduction">Introduction</h1>
<pre><code> OpenSHMEM is a Partitioned Global Address Space (PGAS) library interface
 specification, which is the culmination of a standardization effort among
 many implementers and users of SHMEM programming model. SHMEM has a long
 history as a parallel programming model on Cray systems. For the past two
 decades SHMEM library implementation in Cray systems evolved through
 different generations. Cray OpenSHMEMX is a new SHMEM implementation for
 current and future generation Cray systems.

 Cray OpenSHMEMX release version 8.0.0 is the first official release of
 the Cray OpenSHMEMX library, it is a proprietary SHMEM implementation from
 Cray Inc which is OpenSHMEM standards compliant.

 The current version of Cray OpenSHMEMX is not released as a replacement
 library for the existing Cray SHMEM library. Cray OpenSHMEMX is released
 as a separate product from Cray SHMEM on different Cray systems with
 plans to supersede the existing Cray SHMEM library in near future.</code></pre>
<h1 id="description">Description</h1>
<pre><code> The logically shared, distributed memory access (SHMEM) routines
 provide low-latency, high-bandwidth communication for use in highly
 parallelized scalable programs.

 The SHMEM data-passing library routines are similar to the message
 passing interface (MPI) library routines: they pass data between
 cooperating parallel processes. The SHMEM data-passing routines can be
 used in programs that perform computations in separate address spaces
 and that explicitly pass data to and from different processing
 elements (PEs) in the program.

 The SHMEM parallel programming model assumes an MPI-1 like group of
 processes that runs in parallel from job launch to job termination. No
 processes can be added or removed from this group and all processes
 execute the same application. Thus, SHMEM applications are of the SPMD
 (Single Program Multiple Data) type. SHMEM is a one-sided message
 passing model in which memory is private to each process.

 The SHMEM routines minimize the overhead associated with data passing
 requests, maximize bandwidth, and minimize data latency. Data latency
 is the length of time between a PE initiating a transfer of data and a
 PE being able to use the data.

 SHMEM routines support remote data transfer through put operations
 that transfer data to a different PE and get operations that transfer
 data from a different PE. Other supported operations are work-shared
 broadcast and reduction, barrier synchronization, and atomic memory
 operations.

 More information on the SHMEM programming model can be found in the
 OpenSHMEM standard specification documentation. http://openshmem.org</code></pre>
<h1 id="openshmem-compliance">OpenSHMEM Compliance</h1>
<pre><code> Cray OpenSHMEMX is compliant with the OpenSHMEM API Specification Version
 1.4. All Cray specific extensions are prefixed with SHMEMX_ nomenclature
 and placed inside the shmemx.h and shmemx.fh header.

 The following are the list of Cray-specific features available in Cray
 OpenSHMEMX library:

 o  alltoallv and alltoallv_packed collective operation

 o  put with signal operation

 o  thread-hot multithreading features with thread-based memory ordering

 o  teams and team-based collectives

 o  local-node queries</code></pre>
<h1 id="different-available-transport-layers">Different Available Transport Layers</h1>
<pre><code> Cray OpenSHMEMX is designed to be modular to support different transport
 layers for communication. The current version support the following
 transport layers:

 o  SMP-DMAPP - DMAPP for internode and XPMEM for intranode communication</code></pre>
<h1 id="whitepapers">Whitepapers</h1>
<pre><code> Refer Cray Programming Environment Github page:
 https://pe-cray.github.io/whitepapers/ for access to different whitepapers
 related to Cray OpenSHMEMX software stack.</code></pre>
<h1 id="openshmem-c11-generic-interfaces">OpenSHMEM C11-Generic Interfaces</h1>
<pre><code> The Cray OpenSHMEMX library supports the OpenSHMEM C11-Generic interface,
 which is new with OpenSHMEM V1.3. This interface does not add new
 functionality, but allows existing routines to be called with a
 generic name that maps to a type-specific routine based on the type of
 the arguments. Only certain programming environments support the
 C11-Generic interface. As of the time of the Cray OpenSHMEMX V8.0.0
 release, these include:

 o  CCE 8.5 or later; use the -hstd=c11 flag during compilation

 o  GNU 5.1 or later; no additional flags needed

 o  Intel 16.0 or later; use the -std=c11 or -std=c1x flag during
    compilation

 To use the C11-Generic interface, you must use a compiler that
 supports this feature and you must be sure that the first argument to
 the generic routine is one of the types in the list of the type-
 specific routines for that functionality. For example,

   long source[8], dest[8];
   shmem_get(dest, source, 8, 31);

 is a valid use of C11-Generic because shmem_long_get is one of the
 type-specific get routines.</code></pre>
<h1 id="compiling-and-launching-a-shmem-application-on-a-cray-system">Compiling and Launching a SHMEM Application on a Cray System</h1>
<pre><code> To invoke the compiler for all applications, including SHMEM
 applications, use either the cc, CC, or ftn command. Do not use
 vendor-specific compiler commands such as pgcc, as this may result in
 undefined behavior.

 Example:

 In the example below, an application is first compiled, and the
 resulting executable is then launched using 128 processes:</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb10-1" data-line-number="1">     <span class="fu">cc</span> -o test_shmem test_shmem.c</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">     <span class="ex">aprun</span> -n 128 ./test_shmem</a></code></pre></div>
<pre><code> See the aprun(1) man page for more information.</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb12-1" data-line-number="1">     <span class="fu">cc</span> -o test_shmem test_shmem.c</a>
<a class="sourceLine" id="cb12-2" data-line-number="2">     <span class="ex">srun</span> -n 128 ./test_shmem</a></code></pre></div>
<pre><code> See the srun(1) man page for more information</code></pre>
<h2 id="support-for-static-and-dynamic-linking">Support for Static and Dynamic linking</h2>
<pre><code> Cray OpenSHMEMX supports both static and dynamic linking. Loading
 Cray OpenSHMEMX module file automatically retrieves the correct library to
 link and compile against.

 Example:

 In the example below, an application is first compiled with static linking.</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb15-1" data-line-number="1">     <span class="ex">module</span> load cray-openshmemx/<span class="op">&lt;</span>version<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2">     <span class="fu">cc</span> -o test_shmem test_shmem.c</a></code></pre></div>
<pre><code> For dynamic building, users are expected to explicitly load the location
 of the Cray OpenSHMEMX in the LD_LIBRARY_PATH as shown in the example below:</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb17-1" data-line-number="1">     <span class="ex">module</span> load cray-openshmemx/<span class="op">&lt;</span>version<span class="op">&gt;</span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2">     <span class="bu">export</span> <span class="va">LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH</span>:<span class="va">$LD_LIBRARY_PATH</span></a>
<a class="sourceLine" id="cb17-3" data-line-number="3">     <span class="fu">cc</span> -o test_shmem test_shmem.c</a></code></pre></div>
<h2 id="support-on-different-versions-of-cray-linux-environment-cle">Support on different versions of Cray Linux Environment (CLE)</h2>
<pre><code> By default, Cray OpenSHMEMX with SMP-DMAPP transport layer is supported from
 CLE-06-UP04 operating system releases. To enable it on other older operating
 system releases - compile the OpenSHMEM application using the
 -cray-openshmemx-ctx compiler driver option.

      If the code uses static linking:</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb19-1" data-line-number="1">          <span class="fu">cc</span> -cray-openshmemx-ctx -o shmem_ctx_test.x shmem_ctx_test.c</a></code></pre></div>
<pre><code>      If the code uses dynamic linking:</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb21-1" data-line-number="1">          <span class="fu">cc</span> -dynamic -cray-openshmemx-ctx -o shmem_ctx_test.x shmem_ctx_test.c</a></code></pre></div>
<h1 id="general-notes">General Notes</h1>
<h2 id="cray-openshmemx-and-cray-shmem">Cray OpenSHMEMX and Cray SHMEM</h2>
<pre><code> The current version of Cray OpenSHMEMX is not released as a replacement
 library for the existing Cray SHMEM library. Cray OpenSHMEMX is released
 as a separate product from Cray SHMEM on different Cray systems with
 plans to supersede the existing Cray SHMEM library in near future.

 We will continue to provide support for both Cray SHMEM and Cray
 OpenSHMEMX on the supported Cray systems. This support is intended to
 provide stability for the existing Cray SHMEM users to migrate towards
 the new product.</code></pre>
<h2 id="supported-processor-architectures">Supported Processor Architectures</h2>
<pre><code> The following table provides a brief overview of the different supported
 architectures. Apart from providing support for the regular Xeon and
 Xeon Phi systems as Cray SHMEM, Cray OpenSHMEMX provides extended support
 for ARM based systems.

 |-----------------------------|---------------------|---------------------|
 |       Processor Type        |      Cray SHMEM     |   Cray OpenSHMEMX   |
 |-----------------------------|---------------------|---------------------|
 | Intel Xeon                  |     YES(default)    |         YES         |
 | Intel Xeon Phi              |     YES(default)    |         YES         |
 | ARM (AARCH64)               |          NO         |         YES         |
 |-----------------------------|---------------------|---------------------|</code></pre>
<h2 id="zero-length-data-transfer">Zero-length Data Transfer</h2>
<pre><code> Per OpenSHMEM specification 1.2 Annex C, support for zero-length
 transfers is provided for zero-length get and put. Remote memory transfers
 for zero number of elements are accepted, and this support is provided for
 both block and non-blocking transfers. The usage of NULL pointers for data
 transfer usually leads to program abort, but for zero-length transfers,
 the usage of NULL pointers is accepted.</code></pre>
<h2 id="managing-memory-in-cray-openshmemx">Managing Memory in Cray OpenSHMEMX</h2>
<pre><code> Refer shmem_mem_manage(3) for more information on managing memory in
 Cray OpenSHMEMX</code></pre>
<h2 id="interconnect-specific-informations">Interconnect Specific Informations</h2>
<pre><code> On Cray systems with Aries interconnect, SHMEM jobs are limited to a
 maximum of ~123 PEs per node. In the event of network rerouting due to
 link failure, SHMEM applications will not retransmit lost packets;
 instead, they will time-out and then abort. This is expected behavior
 for DMAPP-based applications that use SHMEM, CAF, or UPC code.</code></pre>
<h2 id="cray-thread-hot-and-openshmem-communication-contexts">Cray Thread-hot and OpenSHMEM Communication Contexts</h2>
<pre><code> Refer to shmem_multithreading(3) man page for more information on the
 interacting with OpenSHMEM multithreading features, communication context
 and Cray-specific thread-hot features</code></pre>
<h2 id="cray-openshmemx-locality-awareness">Cray OpenSHMEMX Locality Awareness</h2>
<pre><code> With Cray OpenSHMEMX version 9.0.0, we have support for locality awareness.
 On previous versions, we initialized both the network transport options 
 (DMAPP) and on-node transport (XPMEM) options even on a single-node job. 
 We used environment variables like SHMEM_USE_SMP to toggle the use of 
 on-node data transfers.

 With Cray OpenSHMEMX version 9.0.0, on single-node jobs only on-node
 transport (XPMEM) options are initialized. Users can toggle the usage using
 the following environment variable options: SHMEM_LOCALITY_ONNODE and
 SHMEM_LOCALITY_OFFNODE. Please refer these environment variables in the
 the following section, for more information.

 Cray OpenSHMEMX/9.0.0 breaks compatibility with Cray OpenSHMEMX/8.0.1 and
 other previous versions, as the support for SHMEM_USE_SMP is discontinued.</code></pre>
<h1 id="environment-variables">Environment Variables</h1>
<pre><code> The following environment variables affect SHMEM behavior.</code></pre>
<h2 id="openshmem-standard-specific-environment-variables">OpenSHMEM Standard Specific Environment Variables</h2>
<pre><code> SHMEM_SYMMETRIC_SIZE
           Controls the size (in bytes) per PE of the symmetric heap.
           Memory segments allocated by calls to shmem_malloc() or
           shpalloc() are taken from the symmetric heap. There is no
           other valid way to use memory from the symmetric heap. If
           there is not enough memory left in the symmetric heap to
           satisfy the shmem_malloc() or shpalloc() request, an error
           message is issued and the job is terminated.

           Cray XC systems with DMAPP as underlying communication layer
           support a growable symmetric heap so if SHMEM_SYMMETRIC_SIZE
           is not set then the symmetric heap grows dynamically as needed
           to a maximum of 2 GB per PE.

           Note:  Data objects in the static data segment and bss
           segment are also symmetric objects but are not part of the
           symmetric heap and therefore are not counted in the size of
           the symmetric heap as determined by SHMEM_SYMMETRIC_SIZE.

           The value set in this environment variable is interpreted as
           a number of bytes, unless the number is followed by a char
           that acts as a multiplier, where:


           g or G multiplies by 2**30 (gigabytes)

           k or K multiplies by 2**10 (kilobytes)

           m or M multiplies by 2**20 (megabytes)

           For example, the string 20m returns the integer value
           20*2**20, or 20 megabytes.

           Only one multiplier is recognized, so 20kk will not produce
           the same value as 20m, nor will invalid strings such as 20MB
           produce the desired result.

           Floating point input is recognized during expansion, so that
           20.5m will produce 20.5*2**20, or 20.5 megabytes. Values are
           rounded to the nearest byte.

           Default: not set

 SHMEM_VERSION_DISPLAY
           If set, causes SHMEM to display the Cray OpenSHMEMX version
           number as well as the build date information.

           Default: not enabled</code></pre>
<!---
     SMA_SYMMETRIC_SIZE
               Note:  As per OpenSHMEM 1.4 specification changes, all SMA-
               prefixed environment variables are deprecated; instead, use
               the equivalent SHMEM-prefixed environment variables. Use
               SHMEM_SYMMETRIC_SIZE in place of SMA_SYMMETRIC_SIZE.

               Default: not set

     SMA_VERSION_DISPLAY
               Note:  As per OpenSHMEM 1.4 specification changes, all SMA-
               prefixed environment variables are deprecated; instead, use
               the equivalent SHMEM-prefixed environment variables. Use
               SHMEM_VERSION_DISPLAY in place of SMA_VERSION_DISPLAY.

               Default: not set
--->
<h2 id="cray-openshmemx-setup-and-running-specific-environment-variables">Cray OpenSHMEMX Setup and Running Specific Environment Variables</h2>
<pre><code> SHMEM_ABORT_ON_ERROR
           If set, causes SHMEM to abort and produce a core dump when
           SHMEM detects an error. If not set, SHMEM instead calls
           exit() with a non-zero exit status. Note that the shell
           coredumpsize must be set appropriately to enable core dumps.

           Default: not enabled

 SHMEM_ENV_DISPLAY
           If set, causes SHMEM to display all SHMEM environment
           variables and their current settings at SHMEM initialization
           time.

           Default: not enabled

 SHMEM_ERROR_FILE
           To redirect error messages issued by the SHMEM library to
           stdout, set this variable to stdout.

           Default: stderr

 SHMEM_FREEMEM_THRESHOLD
           Sets the percentage of huge_page_freemem that SHMEM
           initialization allows to be allocated for the four SHMEM
           memory regions. Using a value too close to 100% risks having
           the job killed during execution because there is not enough
           memory left for other purposes.

           Default: 95

 SHMEM_MEMINFO_DISPLAY
           If set, causes SHMEM to display information about the job&#39;s
           memory allocation during initialization. For more
           information about SHMEM memory allocation and management,
           see the MANAGING MEMORY IN SHMEM section of this man page.

           Default: not enabled

 SHMEM_OPTIMIZED_MEMCPY
           Specified which version of memcpy to use. Valid values are:



           0         Use the system (glibc) version of memcpy.

           1         Use an optimized version of memcpy if one is
                     available for the processor being used. In this
                     release, an optimized version of memcpy() is
                     available only for Intel processors.

           2         Use a highly optimized version of memcpy if one is
                     available for the processor being used. In this
                     release, a highly optimized version of memcpy() is
                     available only for Intel Haswell, Broadwell and
                     KNL processors.

                     The optimized versions of memcpy may provide
                     better performance in some areas but may have
                     performance regressions in other areas.

                     The benefits may vary depending on the programming
                     environment and the communication pattern (e.g., a
                     point-to-point or all-to-all pattern) on the node.

           Default: 0

 SHMEM_SYMMETRIC_PARTITION&lt;n&gt;
           SHMEM_SYMMETRIC_PARTITION&lt;n&gt; is supported on CLE 6.0 UP01
           only.

           Creates a symmetric memory partition. The sum of all
           partitions constitutes the symmetric heap. On systems with
           heterogeneous memory, this can be used to have different
           parts of the symmetric heap on different kinds of memory. This
           is used instead of, not in addition to, SHMEM_SYMMETRIC_SIZE.

           **This feature is not available in Cray OpenSHMEMX for now and
           will be updated in later release.**</code></pre>
<h2 id="cray-openshmemx-collectives-specific-environment-variables">Cray OpenSHMEMX Collectives Specific Environment Variables</h2>
<pre><code> SHMEM_ALLTOALL_BLOCK_SIZE
           Specifies the blocksize in bytes for shmem_alltoall and
           shmem_alltoallv to use when strip-mining the data transfers.
           For Cray XE systems, the default varies between 256 and
           1536, depending on the number of PEs being used per node. A
           higher number of PEs per node results in a lower blocksize.
           An optimal blocksize may be dependent on the specific
           network configuration. Valid blocksizes range from -1 to
           MAX_INT, in multiples of eight. The value is interpreted as
           bytes, unless the string ends with a K, indicating
           kilobytes, or M, indicating megabytes. A value of -1
           indicates use of the default value.

           Default: -1 (varies)

 SHMEM_ALLTOALL_SHORT_MSG
           Specifies the threshold in bytes at and below which SHMEM
           attempts to use the SMP-aware alltoall algorithm. A strip-
           mined, non-blocking PUT algorithm is used for larger
           transfers. The SMP-aware algorithm usually performs best for
           small alltoall transfers, but has additional restrictions.
           The SMP-aware algorithm will not be used if the PE subset is
           contained to one node or if the PE subset uses only one PE
           per node. In addition, all nodes in the subset must be
           identical in terms of number of PEs per node, with the
           exception of the last node in the set. The SMP-aware
           algorithm requires (number_of_nodes *
           number_of_PEs_per_node^2 * len_of_msg) extra bytes of
           symmetric memory. This can be controlled via the
           SHMEM_ALLTOALL_SYMBUF_SIZE environment variable.

           Default: 32 bytes

 SHMEM_ALLTOALL_SYMBUF_SIZE
           Specifies the amount of additional symmetric memory
           allocated during shmem initialization, to be used for the
           SMP-aware alltoall algorithm. The value is interpreted as
           bytes, unless the string ends in a K, indicating kilobytes,
           or M, indicating megabytes. See the SHMEM_ALLTOALL_SHORT_MSG
           environment variable description to determine how much
           memory is required.

           Default: 4M

 SHMEM_ALLTOALL_SYNC_FREQ
           Specifies the synchronization frequency (the number of
           outstanding requests) to use for the shmem_alltoall and
           shmem_alltoallv routines when using non-blocking
           transactions. For Gemini systems, the default varies between
           1 and 256, depending on the number of PEs being used per
           node and the blocksize of the transfers. A higher number of
           PEs per node results in a lower synchronization frequency.
           An optimal synchronization frequency may be dependent on the
           specific network configuration. A valid synchronization
           frequency is in the range of -1 to MAX_INT. A value of -1
           indicates use of the default values.

           Default: -1 (varies)

 SHMEM_ALLTOALL_USE_GETS
           By default, shmem_alltoall and shmem_alltoallv use PUTs. If
           this environment variable is set, GETs are used instead.
           This does not apply to the shmem_alltoallv_packed routine.

           Default: not set

 SHMEM_ALLTOALLV_TSIZE_CHK
           Setting this will enable additional error checking for the
           shmem_alltoallv and shmem_alltoallv_packed collective
           routines to help prevent overwriting data in the target
           array. If set to abort or trunc, the user must pass in the
           maximum number of bytes allowed from each PE in the t_sizes
           array for shmem_alltoallv. Using this data, the
           shmem_alltoallv routine will either abort if any PE plans to
           send more than the maximum bytes it is allowed, or truncate
           the data so that it fits in the maximum allowed bytes. If
           truncation occurs, the returned values in t_sizes will
           reflect the truncated values. Allowed values are none, abort
           or trunc.

           Default: none

           Note:  Setting this option may negatively affect
           performance, as additional communication may be necessary.

 SHMEM_COLL_OPT_OFF
           If set, disables collective optimizations that use
           architecture-specific algorithms for some SHMEM collective
           operations. By default, all available collective optimized
           algorithms are enabled.

           To disable all collective optimized algorithms, set
           SHMEM_COLL_OPT_OFF to 1.

           To disable optimized algorithms for selected SHMEM
           collectives, set the value to a comma-separated list of the
           desired collective names. Names are not case-sensitive. Any
           unrecognizable name is flagged with a warning message and
           ignored.

           The following collective names are recognized:
           shmem_alltoall(3), shmem_alltoallv(3),
           shmem_alltoallv_packed(3),shmem_and, shmem_barrier,
           shmem_barrier_all, shmem_broadcast, shmem_max, shmem_min,
           shmem_or, shmem_prod, shmem_sum, and shmem_xor.

           Default: all available collective optimized algorithms are
           enabled

 SHMEM_MASSIVE_BCAST_CUTOFF
           Controls the cutoff size (in bytes) at or above which the
           optimized broadcast algorithm for very large monolithic data
           buffers is enabled. This environment variable is applicable
           only if the SHMEM_USE_OPT_MASSIVE_BCAST environment variable
           is enabled. The value set in this environment variable is
           interpreted as a number of bytes, unless the number is
           followed by a char that acts as a multiplier. The suffixes
           K, M, and G are supported: K (kilobytes) multiplies by 2**10
           , M (megabytes) multiplies by 2**20 , and G (gigabytes)
           multiplies by 2**30. Valid values are between 0 and
           LONG_MAX.

           Default: 16777216 bytes

 SHMEM_REDUCE_CUTOFF_SIZE
           Controls the cutoff size (in bytes) at or above which the
           optimized reduction algorithm is used for collective
           reduction operation. This environment variable is applicable
           only if the SHMEM_USE_LARGE_OPT_REDUCE environment variable
           is enabled.

           The value set in this environment variable is interpreted as
           a number of bytes, unless the number is followed by a char
           that acts as a multiplier. The suffixes K, M, and G are
           supported: K (kilobytes) multiplies by 2**10, M (megabytes)
           multiplies by 2**20, and G (gigabytes) multiplies by 2**30.
           Valid values are between 0 and LONG_MAX.

           Default: 16384 bytes

 SHMEM_TEAM_FREE_ASSO_CHILD
           This variable ensures all active associated child teams are
           destroyed along with the parent team during a
           shmem_team_free operation. All associated team resources
           used by the parent and child teams are freed. Further
           attempt to destroy any child teams associated with this
           parent team will result in an invalid argument error. By
           default, only the parent team is destroyed during a
           shmem_team_free operation.

           Default: 0 (disabled)

 SHMEM_TEAM_SMP_REDUCE
           An optimized shared memory based reduction algorithm for
           team-based reduction operations. If set to 0, the default
           reduction algorithm is used for the team-based reduction
           operation. If set to 1, the shared memory based optimized
           reduction algorithm is used for the team-based reduction
           operation.

           Note:  This optimization is applicable only for team-based
           reduction and not for active-set based reduction operations.
           The usage of this environment variable is independent of
           SHMEM_COLL_OPT_OFF and SHMEM_USE_DMAPP_COLL usage. This
           optimization is effective on teams which are distributed
           across more than one node and at least one node from this
           distribution has more than one-PE per node. If rank
           reordering is selected, this optimization will be disabled.

           Default: 0

 SHMEM_TEAMS_MEM_OPT_LEVEL
           Specifies the level of memory reduction optimizations that
           can be performed on maintaining SHMEM team members.

           Accepted Values: 0: No memory reduction optimizations are
           performed | 1: Based on the size of teams crated, team
           members are maintained in a tightly packed list to avoid
           memory wastage on free bits in those lists.

           Default: 0

 SHMEM_USE_LARGE_OPT_REDUCE
           An optimized reduction algorithm for large data sizes. If
           set to 0, the default reduction algorithm is used for all
           data sizes. If set to 1, an optimized reduction algorithm
           for large data sizes is used. The cutoff for the data size
           is set using SHMEM_REDUCE_CUTOFF_SIZE. The usage of this
           environment variable is independent of SHMEM_COLL_OPT_OFF
           and SHMEM_USE_DMAPP_COLL usage.

           Default: 0

 SHMEM_USE_OPT_MASSIVE_BCAST
           An optimized broadcast algorithm for very large monolithic
           data sizes. If set to 0, the default broadcast algorithm
           selection is done based on the data sizes. If set to 1, an
           optimized algorithm is used. The algorithm enabled by this
           environment variable is tuned specifically for very large
           monolithic data sizes of 16MB and above. The cutoff data
           size is set using SHMEM_MASSIVE_BCAST_CUTOFF. The usage of
           this environment variable is independent of
           SHMEM_COLL_OPT_OFF and SHMEM_USE_DMAPP_COLL usage.

           Default: 0

 SHMEM_USE_OPTIMIZED_VSMSG_BCAST
           If set, this variable enables the use of an optimized
           shmem_broadcast algorithm for small messages (&lt;=
           (_SHMEM_BCAST_SYNC_SIZE - 1) * sizeof(long)). Setting this
           variable invalidates advice in the shmem_broadcast man page
           which suggests that you can alternate between only two pSync
           arrays on successive calls to shmem_broadcast. If set, the
           user must use some type of synchronization to guarantee that
           the pSync is no longer in use by a previous call to
           shmem_broadcast.

           Default: 0 (not enabled)</code></pre>
<h2 id="cray-openshmemx-multithreading-specific-environment-variables">Cray OpenSHMEMX Multithreading Specific Environment Variables</h2>
<pre><code> SHMEM_MAX_NUM_THREADS
           Specifies the maximum number of threads per process that
           will make Cray OpenSHMEMX calls, if known. If the programmer does
           not know how many threads per process will make Cray OpenSHMEMX
           calls, the environment variable should not be set. This
           environment variable should be set to the correct value to
           get optimal performance from Thread Hot SHMEM. This
           environment variable will be ignored if the provided thread
           safety level is not SHMEM_THREAD_MULTIPLE.

           **This environment variable is effective only on pre-CLE-06-UP04
           builds. Refer to &quot;Support on different versions of Cray Linux
           Environment&quot; in the intro_shmem(3) man page for more information
           on default and pre-CLE-06-UP04 builds for Cray OpenSHMEMX with
           SMP-DMAPP transport layer**

           Default: OMP_NUM_THREADS. If OMP_NUM_THREADS is not set,
           DMAPP default max threads will be used.

 SHMEM_THREAD_SAFETY
           Environment variable to display the OpenSHMEM thread safety level
           This environment variable acts as output to retrieve the
           application thread-safety level during runtime</code></pre>
<h2 id="cray-openshmemx-communication-context-environment-variables">Cray OpenSHMEMX Communication Context Environment Variables</h2>
<pre><code> SHMEM_MAX_CTX
           Sets the maximum number of contexts required per process, if
           known. If the programmer does not know how many contexts will be
           created, the environment variable should not be set. This
           environment variable should be set to the correct value to get
           optimal performance from both the single and multithreaded
           application.

           **This environment variable is effective only on default builds.
           Refer to &quot;Support on different versions of Cray Linux Environment&quot;
           in the intro_shmem(3) manpage for more information
           on default and pre-CLE-06-UP04 builds for Cray OpenSHMEMX library
           with SMP-DMAPP transport layer**

           Default:
           Application initialized with SHMEM_THREAD_SINGLE - 1

           Application initialized with SHMEM_THREAD_MULTIPLE - Dynamically
           calculated maximum number of available network resource available
           per PE in the node. Number of available network resource depends
           on the total number of PEs per node.</code></pre>
<h2 id="cray-openshmemx---smp-communication-layer-specific-environment-variables">Cray OpenSHMEMX - SMP Communication Layer Specific Environment Variables</h2>
<pre><code>SHMEM_LOCALITY_ONNODE
           Enables or disable on-node SMP copies via XPMEM. This variable
           is enabled by default if there are more than one PEs per node
           and the system supports XPMEM transport. 

           Default: 0/1 (enabled/disabled) based on the job configuration

SHMEM_LOCALITY_OFFNODE
           Enables or disables using off-node network data transfers. This
           variable is enabled by default, if the PEs span across multiple
           nodes.

           Default: 0/1 (enabled/disabled) based on the job configuration

 SHMEM_SMP_SIZE_LIMIT
           Sets the maximum size in bytes for on-node SMP copies via
           XPMEM. If set to zero, on-node copy is disabled and all
           traffic is routed through DMAPP (the GNI network). If set to
           a negative value, the maximum size is unlimited and all on-
           node traffic is routed through XPMEM. In the case of strided
           puts and gets, the size limit is compared to the actual
           number of bytes to be put or gotten. The value is
           interpreted as bytes, unless the string ends in a k or K,
           which indicates kilobytes, or an m or M, which indicates
           megabytes.

           Default: -1 (unlimited)

 SHMEM_USE_SMP
           Support for this environment variable is discontinued. Please
           refer to SHMEM_LOCALITY_ONNODE and SHMEM_LOCALITY_OFFNODE to
           achieve similar functionality.
           
           Enables or disable on-node SMP copies via XPMEM. If disabled,
           on-node copy is disabled and all traffic is routed through the
           network.

           Default: 1 (enabled)</code></pre>
<h2 id="cray-openshmemx---dmapp-communication-layer-specific-environment-variables">Cray OpenSHMEMX - DMAPP Communication Layer Specific Environment Variables</h2>
<pre><code> SHMEM_DMAPP_BTE_THRESHOLD
           Specifies the threshold in bytes above which SHMEM switches
           to using the DMA engine for off-node data transfers. Some
           applications may perform better if this value is increased.
           The value is interpreted as bytes, unless the string ends
           with a K, indicating kilobytes, or M, indicating megabytes.

           Default: DMAPP runtime default, which may be based on the
           job configuration

 SHMEM_DMAPP_GLOBAL_EXIT
           If not set or set to 1, enables the OpenSHMEM API Version
           1.2 routine shmem_global_exit(). If set to 0,
           shmem_global_exit() is disabled and a call to
           shmem_global_exit() behaves as a call to exit().

           Default: enabled

 SHMEM_DMAPP_PUT_NBI
           The SHMEM standard allows users to reuse the local buffer
           from a shmem_put() request on return from the call. However,
           the global visibility of the put operation is not guaranteed
           until a shmem_fence() or shmem_barrier[_all]() call is
           completed.

           If SHMEM_DMAPP_PUT_NBI is set to 1, non-blocking DMAPP APIs
           are used. The shmem_put() will be complete when the local
           buffer is available for reuse but the operation may not have
           completed remotely.

           If set to 0, blocking DMAPP APIs are used. The shmem_put()
           will not complete until it is globally visible.

           An application that has concerns or requirements for strict
           completion ordering should use shmem_fence()/shmem_quiet()
           or shmem_barrier[_all]() to explicitly guarantee that
           operations have completed and are globally visible.

           Default: 1

 SHMEM_DMAPP_OPT_CTX_BUILD
           Output label to determine the library used by the application.
           On compiling the OpenSHMEM application with -cray-openshmemx-ctx
           compiler driver option this environment variable will be set to
           1 to denote an optimized DMAPP build with communication contexts
           is used.

 SHMEM_GLOBAL_EXIT_QDEPTH
           Specifies the size of the queue used by shmem_global_exit().
           The queue needs to be large enough to handle all possible
           concurrent calls to shmem_global_exit(). If only one PE is
           expected to call shmem_global_exit(), a value of 2 is
           sufficient. The value must be a power-of-two.

           Default: closest power-of-two value greater than or equal to
           the number of PEs in the job

 SHMEM_MAX_OUTSTANDING_NB
           Specifies the maximum number of outstanding non-blocking
           requests that a rank can issue. The valid range is from 5 to
           4096, inclusive. This value does not normally need to be
           changed, but can be increased if a user application
           encounters as DMAPP_RC_NO_SPACE error during non-blocking
           communications.

           Default: DMAPP runtime default, which may be based on the
           job configuration

 SHMEM_ROUTING_MODE
           Changes the DMAPP (GNI network) routing mode that is
           specified to dmapp_init(). The supported values are:

           0         Set the routing mode to DMAPP_ROUTING_IN_ORDER.

           1         Set the routing mode to
                     DMAPP_ROUTING_DETERMINISTIC.

           2         Set the routing mode to DMAPP_ROUTING_ADAPTIVE.

           Default: 2

 SHMEM_USE_DMAPP_COLL
           If set, enables the use of DMAPP collectives for barrier,
           reduction, and broadcast collective operations on Aries
           systems. If resources permit, the Aries collective engine
           will be used.

           Default: 1</code></pre>
<!---
     XT_SYMMETRIC_HEAP_SIZE
               This is equivalent to SHMEM_SYMMETRIC_SIZE but per OpenSHMEM
               Specification V1.4 (and later), SHMEM_SYMMETRIC_SIZE should be
               used to control the size (in bytes) per PE of the symmetric
               heap. The support for XT_SYMMETRIC_HEAP_SIZE in Cray OpenSHMEMX
               is provided for backward compatibility. If both
               SHMEM_SYMMETRIC_SIZE and XT_SYMMETRIC_HEAP_SIZE values are
               specified, the value from SHMEM_SYMMETRIC_SIZE will be used
               and the value of XT_SYMMETRIC_HEAP_SIZE will be ignored.
--->
<h2 id="external-library-specific-environment-variables">External Library Specific Environment Variables</h2>
<pre><code> PMI_EXIT_QUIET
           If set, disables printing of PMI (Process Management
           Interface) debugging information when a rank in the job
           terminates abnormally.

           Default: debugging information is printed

 PMI_JOB_IS_SPMD
           If set, SHMEM treats a job launched via the ALPS MPMD format
           as an SPMD job instead. This enables SHMEM jobs launched
           using the syntax aprun -n X ./a.out : -n Y ./a.out to run on
           Cray XE systems. This type of launch may be desired in order
           to assign extra resources such as memory to one or more PEs
           in the job.

           Note:  SHMEM does not support MPMD launches with different
           executables on Cray XE systems. When using this environment
           variable, take care to make certain that the executables are
           identical. If they are not identical, unpredictable results
           will occur.

           Default: not enabled

 PMI_LABEL_ERROUT
           If set, causes PMI to pre-pend the corresponding rank to
           each line of stdout and stderr by piping it through the PMI
           daemon for processing. Labeling is intended for debugging
           purposes and may affect performance if enabled.

           This option is only supported for use with the aprun
           launcher. Slurm does not use the PMI daemon and already
           supports a native option (e.g. srun --label). Likewise,
           setting the PMI_NO_FORK option will disable labeling since
           it disables the PMI daemon.

           The PMI output labeling feature is only available when using
           programming models that use PMI such as MPICH or SHMEM.
           Labeling is supported for use with any supported compiler,
           the C and Fortran languages, although in theory it is
           compiler and language independent. Enabling CCE output
           labeling (by setting CRAY_RANK_THREAD_PREFIX) will disable
           PMI labeling since both perform similar functions.

           Under rare circumstances output may be lost. In many such
           cases PMI will warn the user. However, in the event the
           application is terminated by force, output could be lost
           without warning if the PMI daemon is killed before the
           application.

           Note:  Labeling is not supported on Service MAMU nodes.

           Example

           $ export PMI_LABEL_ERROUT=1
           $ cc -o rank rank.c
           $ aprun -n 8 -N 4 ./rank
           0: PMI Label Err/Out Test
           0: Application sees rank: 0
           1: Application sees rank: 1
           2: Application sees rank: 2
           3: Application sees rank: 3
           4: Application sees rank: 4
           5: Application sees rank: 5
           6: Application sees rank: 6
           7: Application sees rank: 7

           Default: not enabled

 PMI_LABEL_ERROUT_FORMAT
           If set, causes PMI to treat the assigned value as the
           err/out label format, which it expands for each rank using
           the character sequences provided below. If an expanded label
           exceeds the maximum length of 40 characters, the program
           will fail abruptly with an error indicating so.

           As an augmentation of err/out labeling, this feature will
           only be enabled when PMI_LABEL_ERROUT is set. When
           PMI_LABEL_ERROUT_FORMAT is not set, err/out labeling will
           function normally, using a default format. Labeling is
           intended for debugging purposes and may affect performance
           if enabled.

           Interpreted sequences are:

           o  %% a literal %

           o  %l local rank of the current PE

           o  %L total number of PEs on the current node

           o  %r global rank of the current PE

           o  %R total number of PEs

           Example

           $ export PMI_LABEL_ERROUT=1
           $ export PMI_LABEL_ERROUT_FORMAT=&quot;[%r of %R]  &quot;
           $ cc -o rank rank.c
           $ aprun -n 8 -N 4 ./rank
           [0 of 8]  PMI Label Err/Out Test
           [0 of 8]  Application sees rank: 0
           [1 of 8]  Application sees rank: 1
           [2 of 8]  Application sees rank: 2
           [3 of 8]  Application sees rank: 3
           [4 of 8]  Application sees rank: 4
           [5 of 8]  Application sees rank: 5
           [6 of 8]  Application sees rank: 6
           [7 of 8]  Application sees rank: 7

           Default: not enabled

 PMI_NO_FORK
           PMI (Process Management Interface) is the interface between
           the launcher and the SHMEM user processes. By default, PMI
           creates a daemon process on each node to monitor the SHMEM
           processes on that node. The PMI daemon forks off child
           processes that become the SHMEM user processes.

           In some cases, it is desirable to avoid having a PMI daemon
           process on each node calling fork to create the SHMEM
           processes, as this sequence may cause confusion for some
           launch scenarios. Setting the PMI_NO_FORK environment
           variable bypasses the PMI daemon and forking procedure. If
           set, the executables launched by the launcher become the
           SHMEM user processes.

           Default: not enabled</code></pre>
<h1><a href="../main.html">Index</a></h1></body>
</html>
